---
layout: archive
title: "CV Files"
permalink: /Files/
author_profile: true
---


Here are some projects I have worked on over the years, often carried out as part of my classes or research activities.


---

### State Representation Learning for Deep Reinforcement Learning ([PDF](https://o2-ch4.github.io/files/Thesis_SRL.pdf))
Thesis version of my survey article on State Representation Learning for Deep Reinforcement Learning.


---


### Avoiding Collapses in Non-Contrastive SSL Methods ([PDF](https://o2-ch4.github.io/files/Report_SSL.pdf))
Investigated how recent non-contrastive self-supervised learning (SSL) methods prevent collapse and maximize representation information without negative pairs. Focused on architectural changes and loss regularizations enabling high information content in representations.

---

### Neural Decoding from Primary Motor Cortex

- **Behavior Decoding**: Designed a vision system to track free-behaving rats implanted with microelectrode arrays. After recording sessions, neural signals were processed to extract spike trains and paired with corresponding behaviors. RNN-based neural decoders were then trained to classify these behaviors. ([PDF](https://o2-ch4.github.io/files/BCI_B_Decoding.pdf))

- **Force Decoding**: Trained neural decoders to predict applied force on a knob sensor from rat motor cortex activity using different LSTM architectures and loss formulation. 

- **Kinematics Decoding**: Developed a pipeline to decode kinematic targets from intra-cortical neural recordings using deep recurrent networks. Led a team of research students in creating a codebase for signal processing, dataset generation (customizable by parameters such as temporal resolution and window length), and decoder training.


---


### Inductor Magnetic Energy Estimation Based on Surrogate Models ([PDF](https://o2-ch4.github.io/files/Surrogate_Inductor.pdf))
Explored ML/DL models as fast surrogates to approximate mappings made by Finite-Element Analysis (FEA) for evaluating inductor designs. Used a proprietary dataset of 100,000 samples to predict magnetic energy based on design topology, reducing evaluation time drastically.

---

### Simulation and Optimization of Wood Drying through Deep Reinforcement Learning ([PDF](https://o2-ch4.github.io/files/Wood_Drying.pdf))
Developed a simulator using OpenAI Gym and Simpy to optimize wood drying processes with a Deep-RL agent. Employed PPO with heuristic-guided reinforcement learning to improve resource allocation and demonstrated potential for industrial process optimization.

---

### Neural Combinatorial Solver using Reinforcement Learning ([PDF](https://o2-ch4.github.io/files/WTA_Report.pdf))
Compared end-to-end neural solvers with traditional methods for solving combinatorial optimization problems. Focused on Weapon-Target Assignment (WTA) using a graph attention network and reinforcement learning to learn optimal policies minimizing destructive target values.

---

### Critical Temperature Prediction for Superconducting Materials ([PDF](https://o2-ch4.github.io/files/Superconducting_T.pdf))
Used deep neural networks to predict critical temperatures of superconductors based on features like atomic weights and entropy. Leveraged a dataset of 21,263 materials to map material properties to laboratory-measured critical temperatures.

---

### Theory Behind ML Models + Code Implementations ([PDF](https://o2-ch4.github.io/files/ML_Notebooks.pdf))
Created an 80-page document summarizing machine learning models with theoretical explanations and Python code implementations. Compiled from 20 books and various papers, it also served as a learning resource for friends.


---

### Theory Scientific Computing in Julia + Code Implementations ([PDF](https://o2-ch4.github.io/files/Julia_Notebooks.pdf))
Created a 27-page document on scientific computing with Julia, covering mathematical modeling, numerical methods (ODEs, PDEs, SDEs), and hybrid techniques like PINNs, with practical examples and Julia code implementations.

---

### Trade-offs Between Model-Free and Model-Based Reinforcement Learning Methods
Explored trade-offs between model-free and model-based RL approaches, with a focus on implementing and understanding MuZero, highlighting its ability to combine planning and learning efficiently.

---
---
---
---
---


### More Documents

(loading)


